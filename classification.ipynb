{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from mat file\n",
    "# mat = scipy.io.loadmat(\"exampleEMGdata180trial_train.mat\")\n",
    "\n",
    "# load feature data from csv\n",
    "features = pd.read_csv('feature_table.csv')\n",
    "# test_features = pd.read_csv('test_features.csv')\n",
    "# test_features = pd.read_csv('feature_table.csv')\n",
    "\n",
    "# make individual label tensor / column\n",
    "labels = features.pop('labels')\n",
    "# test_labels = test_features.pop('labels')\n",
    "\n",
    "# test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make rms features\n",
    "rms_headers = [f\"RMS ch {num}\" for num in [x+1 for x in range(4)]]\n",
    "rms_features = features[rms_headers]\n",
    "\n",
    "# make wl features\n",
    "wl_headers = [f\"WL ch {num}\" for num in [x+1 for x in range(4)]]\n",
    "wl_features = features[wl_headers]\n",
    "\n",
    "# make var features\n",
    "var_headers = [f\"VAR ch {num}\" for num in [x+1 for x in range(4)]]\n",
    "var_features = features[var_headers]\n",
    "\n",
    "# make iemg features\n",
    "iemg_headers = [f\"IEMG ch {num}\" for num in [x+1 for x in range(4)]]\n",
    "iemg_features = features[iemg_headers]\n",
    "\n",
    "# make mf features\n",
    "mf_headers = [f\"MF ch {num}\" for num in [x+1 for x in range(4)]]\n",
    "mf_features = features[mf_headers]\n",
    "\n",
    "# make pf features\n",
    "pf_headers = [f\"PF ch {num}\" for num in [x+1 for x in range(4)]]\n",
    "pf_features = features[pf_headers]\n",
    "\n",
    "# make best feature\n",
    "best_feature = pd.concat([mf_features, pf_features], axis=1, join='inner')\n",
    "\n",
    "# make mf test features\n",
    "# test_mf_features = test_features[mf_headers]\n",
    "\n",
    "# make pf test features\n",
    "# test_pf_features = test_features[pf_headers]\n",
    "\n",
    "# make best test feature\n",
    "# test_best_feature = pd.concat([test_mf_features, test_pf_features], axis=1, join='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(feature, label):\n",
    "\n",
    "#     METRICS = [\n",
    "#       tf.keras.metrics.CategoricalAccuracy(name='accuracy')\n",
    "# ]\n",
    "\n",
    "    normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "\n",
    "    normalizer.adapt(feature)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        normalizer,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(2187, activation='relu'),\n",
    "        tf.keras.layers.Dense(729, activation='relu'),\n",
    "        tf.keras.layers.Dense(243, activation='relu'),\n",
    "        tf.keras.layers.Dense(81, activation='relu'),\n",
    "        tf.keras.layers.Dense(27, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=tf.keras.metrics.CategoricalAccuracy(name='accuracy'))\n",
    "\n",
    "    model.fit(feature, label, epochs=50)\n",
    "\n",
    "    loss, acc = model.evaluate(feature, label)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rms_acc = get_accuracy(rms_features, labels)\n",
    "# wl_acc = get_accuracy(wl_features, labels)\n",
    "# var_acc = get_accuracy(var_features, labels)\n",
    "# iemg_acc = get_accuracy(iemg_features, labels)\n",
    "# mf_acc = get_accuracy(mf_features, labels)\n",
    "# pf_acc = get_accuracy (pf_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies = [rms_acc, wl_acc, var_acc, iemg_acc, mf_acc, pf_acc]\n",
    "\n",
    "# x = 1\n",
    "# for acc in accuracies:\n",
    "#     plt.bar(x, acc, width=0.5)\n",
    "#     x += 1\n",
    "\n",
    "# plt.xlabel('Feature Type')\n",
    "# plt.ylabel('Training Accuracy')\n",
    "# plt.title('Resubstitution Accuracy of RPS Training Data Features')\n",
    "# plt.legend(['Root Mean Square', 'Waveform Length', 'Variance', 'Integrated EMG', 'Mean Frequency', 'Peak Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_best_acc, train_tp, train_fp, train_tn, train_fn, train_pre, train_re= get_accuracy(best_feature, labels)\n",
    "# test_best_acc, test_tp, test_fp, test_tn, test_fn, test_pre, test_re = get_accuracy(test_best_feature, test_labels)\n",
    "# train_results = get_accuracy(best_feature, labels)\n",
    "# test_results = get_accuracy(test_best_feature, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mampane\\OneDrive - Olin College of Engineering\\Desktop\\Olin\\Second Year First Semester\\Neurotech\\rps_classifier\\rps_classifier\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:5729: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1019 - accuracy: 0.3111\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.0690 - accuracy: 0.4389\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.0435 - accuracy: 0.4056\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.0188 - accuracy: 0.4278\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9924 - accuracy: 0.4500\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9625 - accuracy: 0.5611\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9578 - accuracy: 0.5278\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9256 - accuracy: 0.5389\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9059 - accuracy: 0.5667\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8904 - accuracy: 0.6111\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8606 - accuracy: 0.6222\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8567 - accuracy: 0.6278\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8243 - accuracy: 0.6278\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8105 - accuracy: 0.6278\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8131 - accuracy: 0.6167\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7721 - accuracy: 0.6389\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.7470 - accuracy: 0.6667\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7122 - accuracy: 0.7056\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.7111\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6801 - accuracy: 0.6889\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mampane\\OneDrive - Olin College of Engineering\\Desktop\\Olin\\Second Year First Semester\\Neurotech\\rps_classifier\\rps_classifier\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:5729: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    }
   ],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "\n",
    "normalizer.adapt(best_feature)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(729, activation='relu'),\n",
    "    tf.keras.layers.Dense(243, activation='relu'),\n",
    "    tf.keras.layers.Dense(81, activation='relu'),\n",
    "    tf.keras.layers.Dense(27, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            # metrics=tf.keras.metrics.CategoricalAccuracy(name='accuracy')\n",
    "            metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "model.fit(best_feature, labels, epochs=20)\n",
    "\n",
    "loss, acc = model.evaluate(best_feature, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_vector = model.predict(best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(prediction_vector[0]).index(max(prediction_vector[0]))\n",
    "# list(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = [list(prediction_vector[idx]).index(max(list(prediction_vector)[idx])) for idx in range(len(prediction_vector)) if list(prediction_vector[idx]).index(max(list(prediction_vector)[idx])) == labels[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_predictions)/len(prediction_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
